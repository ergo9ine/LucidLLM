# LucidLLM Chat

[English](README.md) | [한국어](README.ko.md) | [简体中文](README.zh-CN.md) | [日本語](README.ja.md)

![License](https://img.shields.io/github/license/ergo9ine/LucidLLM)
![Transformers.js](https://img.shields.io/badge/Transformers.js-v3.8.1-yellow)
![WebGPU](https://img.shields.io/badge/WebGPU-Supported-green)
![PWA](https://img.shields.io/badge/PWA-Planned-blue)

**LucidLLM** は、ブラウザ上で完全に実行されるローカル大規模言語モデル（LLM）チャットアプリケーションです。[Transformers.js](https://huggingface.co/docs/transformers.js) と WebGPU 技術を使用して、データを外部サーバーに送信することなく、ブラウザ内で AI モデルを安全に実行します。

> **主な特徴:** 18,200+ ラインコード • 4 言語対応 • WebGPU/WASM 推論 • トークンストリーミング • カスタム仮想 DOM • AES-256 暗호화 バックアップ • OPFS モデルキャッシング

## ✨ 主な機能

### 🤖 AI・モデル

| 機能 | 説明 |
|------|------|
| **完全ローカル推論** | すべての AI 推論はブラウザ内で実行され、データはデバイスから流出しません |
| **WebGPU 加速** | GPU 加速推論をサポート、非対応デバイスは WASM に自動フォールバック |
| **OPFS モデルキャッシング** | Origin Private File System でモデルを永続保存、再ダウンロード不要 |
| **モデルダウンロードマネージャー** | 一時停止/再開、指数バックオフ再試行、量子化レベル選択をサポート |
| **複数モデル対応** | キャッシュされた複数の ONNX モデルをロードして切り替え |
| **モデルカード表示** | モデルメタデータを表示（アップローダー、タスク、ダウンロード、ライセンス、いいね、タグ、説明） |
| **Hugging Face 統合** | Hugging Face モデルハブから直接モデルを照会してダウンロード |

### 💬 チャット体験

| 機能 | 説明 |
|------|------|
| **マルチセッションチャット** | 独立した会話履歴を持つ複数のチャットタブをサポート |
| **リアルタイムトークンストリーミング** | リアルタイムトークン生成とストリーミング表示 |
| **トークン速度統計** | 平均/最大/最小 トークン/秒を表示 |
| **メモリ使用量表示** | リアルタイムメモリ消費モニタリング |
| **システムプロンプトエディター** | アシスタントの動作をカスタマイズ（最大 20 行） |
| **コンテキストウィンドウ制御** | 4k、8k、16k、32k、128k コンテキストサイズを選択 |
| **チャットエクスポート** | 会話を JSON ファイルでエクスポート |
| **自動スクロール** | 自動下端スクロールと手動オーバーライドボタン |

### 🔒 プライバシー・バックアップ

| 機能 | 説明 |
|------|------|
| **Google Drive バックアップ** | 設定とチャット履歴を Google Drive に暗号化バックアップ |
| **AES-GCM-256 暗号化** | PBKDF2 キー誘導（250,000 ラウンド）によるクライアントサイド暗号化 |
| **Gzip 圧縮** | バックアップペイロードのオプション圧縮 |
| **自動バックアップ** | 変更発生時に自動バックアップ（25 秒デバウンス） |
| **バックアップ復元** | 以前のバックアップスナップショットから上書きオプションで復元 |
| **バックアップバージョン管理** | Drive に複数のバックアップバージョンを維持 |
| **サーバー通信なし** | 明示的バックアップ時以外はすべてのデータはローカルに保存 |

### 🌐 ユーザー体験

| 機能 | 説明 |
|------|------|
| **4 言語対応** | 韓国語、英語、日本語、中国語簡体字、自動言語検出 |
| **3 つのテーマ** | ダーク、ライト、OLED ブラック（OLED ディスプレイ用純黒） |
| **レスポンシブデザイン** | モバイルファースト、スマートフォン/タブレット完全対応 |
| **PWA 対応** | プログレッシブウェブアプリ機能 (計画中) |
| **サイドバーナビゲーション** | チャットおよびワークスペースパネル付き折りたたみ式サイドバー |
| **キーボードショートカット** | Ctrl+Shift+N（新規チャット）、Ctrl+Shift+E（エクスポート）、Ctrl+B（サイドバー切り替え） |

## 📋 要件

### ブラウザ要件

| 要件 | 詳細 |
|------|------|
| **最小ブラウザ** | Chrome 113+ / Edge 113+（WebGPU 対応） |
| **フォールバック対応** | WASM 対応ブラウザ |
| **セキュリティコンテキスト** | HTTPS または localhost が必要 (OPFS) |
| **JavaScript** | ES2020+ モジュール対応 |

### ハードウェア要件

| 構成要素 | 最小 | 推奨 |
|----------|------|------|
| **RAM** | 4GB | 8GB+ |
| **ストレージ** | モデルあたり 100MB - 2GB | SSD 推奨 |
| **GPU** | 統合グラフィックス | WebGPU 対応専用 GPU |

### 推奨モデル

| モデル | サイズ | 量子化 | 用途 |
|--------|--------|--------|------|
| SmolLM2-135M-Instruct | ~135M | FP32, BNB4 | テスト/開発 |
| Qwen2.5-0.5B-Instruct | ~500M | Q4_K_M | バランスの取れたパフォーマンス |
| Phi-3-mini-4k-instruct | ~3.8B | Q4_K_M | 高品質レスポンス |

## 🚀 はじめに

### ホスト版

インストールなしで GitHub Pages デプロイを直接使用：

👉 **[ライブデモ](https://ergo9ine.github.io/LucidLLM/)**

### ローカル実行

1. **リポジトリをクローン**

```bash
git clone https://github.com/ergo9ine/LucidLLM.git
cd LucidLLM
```

2. **ローカルサーバーを実行**

OPFS およびサービスワーカーの使用にはセキュリティコンテキスト（HTTPS または localhost）が必要です。

```bash
# Python
python -m http.server 8000

# Node.js (npx)
npx serve .

# または含まれている npm スクリプトを使用
npm run serve
```

3. **ブラウザでアクセス**

`http://localhost:8000`（または使用したポート）にアクセスします。Chrome または Edge を推奨します。

### 開発依存関係（オプション）

```bash
npm install
```

ランタイム依存関係（Transformers.js、Tailwind CSS、Lucide Icons、Google Fonts）は CDN からロードされるため、別のビルドプロセスは不要です。

## 📖 使用ガイド

### 1. モデルをロードする

1. ヘッダーの**設定**ボタン（⚙️）をクリックします。
2. **モデル管理**タブに移動します。
3. Hugging Face モデル ID を入力します（例：`onnx-community/SmolLM2-135M-Instruct`）。
4. **取得**をクリックしてモデル情報を取得します。
5. ドロップダウンから量子化レベルを選択します。
6. **ダウンロード**をクリックしてモデルを OPFS にキャッシュします（一時停止/再開対応）。
7. ダウンロード完了後、**有効化**をクリックしてモデルをロードします。

### 2. チャットを開始する

1. 下部の入力フィールドにメッセージを入力します。
2. **送信**をクリックするか、`Enter` キーを押して送信します。
3. タブバーの**+**ボタンを使用して新規チャットセッションを作成します。
4. チャットタブをクリックしてセッションを切り替えます。

### 3. LLM 設定を構成する

**設定 > LLM 設定**に移動：

| 設定 | デフォルト | 範囲 | 説明 |
|------|------------|------|------|
| **システムプロンプト** | "You are a helpful assistant." | 最大 20 行 | アシスタントの動作を定義 |
| **最大出力トークン** | 512 | 1 - 32,768 | レスポンスの長さを制御 |
| **コンテキストウィンドウ** | 8k | 4k/8k/16k/32k/128k | コンテキストサイズを選択 |
| **Temperature** | 0.9 | 0.1 - 2.0 | レスポンスのランダム性 |
| **Top P** | 0.9 | 0.1 - 1.0 | ヌクレウスサンプリング |
| **Presence Penalty** | 0 | -2.0 - 2.0 | 繰り返し制御 |

### 4. 推論デバイスの選択

ヘッダー右側のドロップダウンで切り替え：

- **⚡ WebGPU** — GPU 加速推論（パフォーマンス推奨）。
- **🧩 CPU (WASM)** — WebGPU 非対応ブラウザ用のフォールバック。

### 5. Google Drive バックアップ

1. **設定 > バックアップと復元**に移動します。
2. Google OAuth クライアント ID を入力します（オプション：クライアントシークレット）。
3. **Google Drive を接続**をクリックして認証します。
4. **変更時に自動バックアップ**を有効にして自動バックアップ。
5. **今すぐバックアップ**を使用して手動バックアップ。
6. **復元**ボタンを使用して以前のバックアップスナップショットから復元します。

## 🏗️ プロジェクト構造

```
LucidLLM/
├── index.html                  # メイン HTML エントリーポイント (728 ライン)
├── bootstrap.js                # アプリ初期化 (62 ライン)
├── main.js                     # コアアプリケーションロジック (~12,600 ライン)
├── i18n.js                     # 国際化モジュール (~2,050 ライン、4 言語)
├── shared-utils.js             # 共有ユーティリティおよびグローバル API (~450 ライン)
├── transformers-bridge.js      # Transformers.js インターフェースレイヤー (13 ライン)
├── worker.js                   # 推論用 Web ワーカー (~200 ライン)
├── drive-backup.js             # 暗号化付き Google Drive バックアップ (~250 ライン)
├── style.css                   # カスタムスタイルおよびテーマ定義 (~1,140 ライン)
├── favicon.svg                 # アプリアイコン
├── package.json                # NPM パッケージ設定
├── docs/
│   ├── roadmap.md              # 機能ロードマップ
│   └── compatibility.md        # モデル互換性情報
└── tests/                      # テストスイート (Vitest)
```

**合計：~18,200+ ラインコード**

## 🛠️ 技術スタック

| カテゴリ | 技術 |
|----------|------|
| **言語** | JavaScript (ES2020+ Modules) |
| **アーキテクチャ** | ゼロビルド、Vanilla JS（フレームワークなし） |
| **ML フレームワーク** | Transformers.js v3.8.1 |
| **推論バックエンド** | WebGPU / WASM（自動フォールバック） |
| **ストレージ** | Origin Private File System (OPFS)、localStorage |
| **スタイリング** | Tailwind CSS v3 (CDN) + カスタム CSS 変数 |
| **アイコン** | Lucide Icons (CDN) |
| **フォント** | Space Grotesk (Google Fonts) |
| **オフライン** | 計画中 (サービスワーカー) |
| **バックアップ認証** | Google Identity Services (OAuth 2.0) |
| **暗号化** | Web Crypto API (PBKDF2、AES-GCM-256) |
| **圧縮** | CompressionStream API (Gzip) |
| **CDN** | jsDelivr、unpkg |

## 🔧 設定

### 保存された設定 (localStorage)

| カテゴリ | 設定 |
|----------|------|
| **LLM** | システムプロンプト、最大トークン、コンテキストウィンドウ、HF トークン、temperature、top_p、presence_penalty |
| **プロフィール** | ニックネーム、アバター、言語、テーマ |
| **推論** | 優先デバイス (webgpu/wasm) |
| **バックアップ** | クライアント ID、自動バックアップ、バックアップ制限、最終同期 |

### 主な保存場所

| ストレージ | 目的 |
|------------|------|
| `lucid_user_profile_v1` | ユーザープロフィール（ニックネーム、アバター、言語、テーマ） |
| `lucid_system_prompt` | システムプロンプト設定 |
| `lucid_max_output_tokens` | 最大出力トークン設定 |
| `lucid_context_window` | コンテキストウィンドウサイズ |
| `lucid_inference_device` | 推論デバイス設定 |
| `lucid_google_drive_*` | Google Drive バックアップ設定 |

## 🧪 開発ガイド

### コード規約

- **ES Modules** — すべてのアプリケーションコードは ES Module 構文を使用します。
- **集中状態管理** — グローバル状態は `main.js` の単一 `state` オブジェクトで管理されます。
- **ネイティブアーキテクチャ** — 高性能な動的 UI レンダリングのために、カスタム仮想 DOM (vdom.js) を搭載した Vanilla JS コア。
- **国際化 (i18n)** — 200+ 翻訳キーと階層的フォールバックを提供します。
- **アクセシビリティ** — ARIA 属性、キーボードナビゲーション、フォーカス管理を遵守します。
- **レスポンシブデザイン** — メディアクエリと Tailwind CSS を活用したモバイルファーストアプローチ。

### 主要モジュール

#### `i18n.js` - 国際化

```javascript
import { t, I18N_KEYS, setCurrentLanguage } from './i18n.js';

// 言語設定
setCurrentLanguage('ja');

// 変数を含む翻訳
t(I18N_KEYS.STATUS_MODEL_LOADING, { model: 'SmolLM2' });
// → "SmolLM2 ロード中..."

// DOM に適用
applyI18nToDOM(document);
```

**対応言語:** 韓国語、英語、日本語、中国語簡体字

#### `shared-utils.js` - ユーティリティ

```javascript
import {
    formatBytes,
    formatSpeed,
    formatEta,
    getErrorMessage,
    publishLucidApi
} from './shared-utils.js';

// ファイルサイズをフォーマット
formatBytes(1024 * 1024 * 500);  // → "500 MB"

// 速度をフォーマット
formatSpeed(1024 * 512);  // → "512 KB/s"

// 時間をフォーマット
formatEta(3665);  // → "1 時間"

// グローバル API を公開
publishLucidApi({ myFunction: () => {} });
```

### テストの実行

```bash
# テストスイートを実行
npm test
```

### プロダクションビルド

**ビルドステップ不要！** このアプリケーションはゼロビルドであり、静的ファイルから直接実行されます。

## 🗺️ ロードマップ

### 完了済み

- [x] 遅延読み込み付き最適化 i18n システム (200+ キー)
- [x] i18n 用キーネームスペース定数
- [x] 翻訳用階層的フォールバック構造
- [x] モデルキャッシング用 OPFS fetch インターセプター
- [x] バックアップ用クライアントサイド暗号化
- [x] 独立した履歴を持つマルチセッションチャット
- [x] リアルタイムトークン速度統計

### 進行中

- [x] トークン別出力によるストリーミングレスポンス
- [ ] コード構文強調付き Markdown レンダリング
- [ ] メッセージ編集および再生成

### 計画中

- [ ] マルチモーダル入力（Vision モデルによる画像分析）
- [ ] モデル比較モード
- [ ] 自動量子化推奨
- [ ] ローカル文書用 RAG サポート
- [ ] 関数呼び出しインターフェース
- [ ] 会話分岐 (fork)
- [ ] Web Speech API による音声入出力
- [ ] PWA インストール用 Web App Manifest
- [ ] 長時間推論タスクに対するプッシュ通知

完全なロードマップは [docs/roadmap.md](docs/roadmap.md) を参照してください。

## 🤝 貢献

貢献は常に歓迎します！バグを見つけたり、新機能を提案したい場合は、Issue を登録するか Pull Request を送信してください。

### 貢献方法

1. このリポジトリを**フォーク**します。
2. `main` ブランチから機能ブランチを作成します：
   ```bash
   git checkout -b feature/your-feature
   ```
3. **既存のコードスタイル**に従います：
   - ES Modules
   - フレームワークなし
   - 直接 DOM 操作
4. 新しいユーティリティ関数については `tests/` ディレクトリに**テストを追加**します。
5. ブラウザで機能をテストします：
   - モデルロード
   - チャットワークフロー
   - 設定管理
6. **コミットしない**：
   - `node_modules/`
   - エディタ設定
   - ビルド成果物
7. 変更をコミットし、Pull Request を作成します。

### Issue 報告

GitHub Issue を登録する際に以下の情報を含めてください：

- ブラウザ名およびバージョン
- OS およびバージョン
- 再現手順
- 予想動作 vs 実際の動作
- コンソールエラーログ（該当する場合）
- スクリーンショット（該当する場合）

### 互換性報告

量子化レベルによっては、一部のモデルは WASM または WebGPU 環境と互換性がない場合があります。以下の情報とともに互換性のあるモデルを GitHub Issues に登録してください：

- モデル名
- リポジトリ（HF、Github URL）
- 量子化レベル
- バージョンまたはハッシュ
- パフォーマンスメモ（tokens/sec、メモリ使用量）

既知の互換モデルは [docs/compatibility.md](docs/compatibility.md) を参照してください。

## 📊 パフォーマンスベンチマーク

| モデル | デバイス | Tokens/sec | メモリ | 初回トークン |
|--------|----------|------------|--------|--------------|
| SmolLM2-135M | WebGPU | ~45 tok/s | 800 MB | ~2 秒 |
| SmolLM2-135M | WASM | ~8 tok/s | 600 MB | ~5 秒 |
| Qwen2.5-0.5B | WebGPU | ~25 tok/s | 1.2 GB | ~3 秒 |
| Phi-3-mini | WebGPU | ~12 tok/s | 2.5 GB | ~5 秒 |

*パフォーマンスはハードウェアによって異なります。M2 MacBook Pro でテスト。*

## 🔒 セキュリティ

- **クライアントサイド暗号化** — PBKDF2 キー誘導（250,000 ラウンド）による AES-GCM-256
- **テレメトリなし** — 分析または追跡コードなし
- **ローカルデータ保存** — 明示的バックアップ時以外はすべてのデータはブラウザに保存
- **セキュリティコンテキストが必要** — OPFS/サービスワーカー用 HTTPS または localhost

## 📚 ドキュメント

- [ロードマップ](docs/roadmap.md) - 機能ロードマップおよび計画的な改善
- [互換性](docs/compatibility.md) - モデル互換性情報
- [LICENSE](LICENSE) - MIT ライセンス

## 🌐 国際化 (i18n)

このプロジェクトは 200+ 翻訳キーを持つ `i18n.js` を通じて多言語サポートを提供します。言語はブラウザの言語設定に基づいて自動的に検出され、設定メニューで手動で変更できます。

**対応言語:**
- 🇰🇷 한국어 (韓国語)
- 🇺🇸 English (英語)
- 🇯🇵 日本語
- 🇨🇳 简体中文 (中国語簡体字)

### 新しい言語を追加する

1. `i18n.js` を開きます。
2. 適切なセクションに言語別の翻訳を追加します。
3. `ja` または `zh-CN` が英語から継承する場合はオーバーライドを追加します。
4. `SUPPORTED_LANGUAGES` 配列を更新します。

```javascript
// 例：ドイツ語を追加
const DE_SPECIFIC = {
    [I18N_KEYS.HEADER_SETTINGS]: "Einstellungen",
    [I18N_KEYS.CHAT_PLACEHOLDER]: "Nachricht eingeben...",
    // ...
};
```

## 🏆 注目すべき技術的成果

### 1. 高性能仮想 DOM (Virtual DOM)
複雑な UI アップデート（モデルテーブル、チャットリストなど）を効率的に処理するために、軽量なカスタム仮想 DOM (`vdom.js`) を使用しています。これにより、外部依存なしで高性能なレンダリングが可能になります。

### 2. ゼロビルドアーキテクチャ
アプリケーション全体がビルドプロセスなしで静的ファイルから直接実行されます。すべての依存関係は CDN からロードされます。

### 3. OPFS Fetch インターセプター
カスタム fetch インターセプターが OPFS のキャッシュされたモデルファイルを透過的に提供し、リモート Hugging Face リクエストがローカルファイル読み取りのように見えます。

### 4. 階層的 i18n システム
- `I18N_KEYS` 定数を持つ 200+ 翻訳キー
- 階層的フォールバック：現在 → 英語 → 韓国語
- キャシング付き遅延読み込み辞書
- `data-i18n` 属性による自動 DOM 翻訳

### 5. クライアントサイド暗号化
Web Crypto API を使用した完全なバックアップ暗号化：
- PBKDF2 キー誘導（250,000 ラウンド）
- AES-GCM-256 暗号化
- Gzip 圧縮サポート

### 6. ストリーミングトークン生成
リアルタイムトークンストリーミング：
- ビームサーチコールバック解析
- 増分表示のためのデルタ計算
- トークン速度統計（平均/最大/最小）
- スロットリングされたレンダリング（最大 60 FPS）

### 7. ダウンロードマネージャー
堅牢なダウンロードシステム：
- 一時停止/再開サポート
- 指数バックオフ再試行（3 回再試行、800ms ベース）
- 進捗追跡（速度、予想時間、バイト数）
- マルチファイルモデル用キュー管理

## 📄 ライセンス

このプロジェクトは**MIT ライセンス**の下でライセンスされています - 詳細は [LICENSE](LICENSE) ファイルを参照してください。

## 🙏 謝辞

- [Hugging Face](https://huggingface.co/) - Transformers.js およびモデルホスティング
- [Transformers.js](https://huggingface.co/docs/transformers.js) - ブラウザ内 ML 推論
- [Tailwind CSS](https://tailwindcss.com/) - ユーティリティファースト CSS フレームワーク
- [Lucide Icons](https://lucide.dev/) - 美しいアイコン
- [Space Grotesk](https://fonts.google.com/specimen/Space+Grotesk) - フォントファミリー

---

**プライバシー重視の AI のために ❤️ で作成**

[⬆ トップへ](#lucidllm-chat)
